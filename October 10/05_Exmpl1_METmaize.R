
#' ---
#' title: "Genotype X Environment"
#' author: "Dr C. Ben, Prof. L. Gentzbittel"
#' date: "March 2022"
#' numbersections: true
#' papersize: a4
#' geometry: margin=1.8cm
#' header-includes:
#'   - \usepackage{graphicx}
#'   - \usepackage{amsmath}
#'   - \usepackage{bbold}
#'   - \def\*#1{\mathbf{#1}}
#'   - \def\one{{\mathbb{1}}}
#'   - \def\iid{\mathop{\sim}_{\rm i.i.d.}}
#' ---
#'
#' 
#'   ___
#'

#' As a preliminary to models for G $\times$ E and breeding concepts, it is useful to introduce the concepts of target population of genotypes (TPG) and target population of environments (TPE). The TPG and TPE define the set of genotypes and environments for which we want our inference and predictions to be valid and precise. The TPG contains all possible genotypes we hope to develop and grow the coming years. The TPE delineates the future growing conditions of the genotypes in the TPG. The TPE can be defined by geography, soil and meteorological conditions, management choices, and the incidence of biotic and abiotic stresses. 
#'
#' The statistical methodology is illustrated using a maize data set obtained from a series of drought and nitrogen stress trials from the maize breeding program at Centro Internacional de Mejoramiento de Maiz y Trigo (CIMMYT; the International Maize and Wheat Improvement Center; Ribaut et al., 1996, 1997). The data are released in Malosetti *et al.* (2013). Another smaller data set on the yield data of 1993 Ontario winter wheat performance trials, in which $18$ genotypes (G1 to G18) were tested at nine locations (E1 to E9) will be used, released in Yan and Tinker (2006).
#'
#+ message = FALSE, include = FALSE
# clean memory
rm(list = ls())
gc()
# To erase all graphs
graphics.off()
## do NOT forget for compilation !
library(knitr)

#+ message = FALSE, include = TRUE
# libraries used for the analyses
library(tidyr)
library(dplyr)
library(ggplot2)
library(car)  ## for leveneTest()
library(scales)  ## to modify alpha of colours
library(GGally)  ## to plot pairwise correlations
library(gridExtra)  ## to combine graphics into one device.
# Constraints on effects for ANOVA
options(contrasts=c("contr.treatment", "contr.poly"), scipen = -1)


#+ include = FALSE
opts_chunk$set(fig.align = "center",
               cache = TRUE,
#               cache.lazy = FALSE,
               tidy = TRUE,
               tidy.opts = list(blank = FALSE, width.cutoff = 60),
               fig.width = 5, fig.height = 5,
               dev = 'pdf',
               warning = FALSE,
               include = TRUE)


#'
#' 
#' # The data sets
#' A maize F2 population was generated by crossing a drought tolerant parent (P1) with a drought susceptible one (P2 ). Seeds harvested from each of 211 F2 plants formed F3 families, which were stored for further evaluation. The F3 families were evaluated in managed stress trials in 1992, 1994, and 1996.
#'
#' * In the winter of 1992, a managed water stress trial was conducted in Mexico, including no stress (NS), intermediate stress (IS), and severe stress (SS).
#' * In the winter of 1994, a similar trial was conducted, but it only included the IS and SS treatments.
#' * In the summer of 1996, the families were tested in a nitrogen stress trial with two levels: low (LN) and high nitrogen (HN).
#' * An extra LN trial was conducted in the winter of the same year.
#'
#' In total, the families were evaluated in eight different environments, each environment characterized by year, stress type and intensity, and management factors. Grain yield is recorded, as well as the minimum temperature during flowering (MINTF) and the amount of radiation during grain filling (RADG).
#' 
#' ## Single-step or two-step of analysis.
#' 
#' We do *not* know which experimental designs were used in each of 1992, 1994 and both 1996 experiments : the means by genotype and by environment are provided 'as is', not the raw data. These values come from a first stage of analysis -- per environment -- that compute 'adjusted means' per environment.
#'
#' This example is thus typical of a so-called two-stage strategy for analyzing MET data. In the first stage, individual trials are analyzed with models including terms for design features and spatial variation. From these individual trial analyses, adjusted means and weights -- usually reciprocals of the variances of the means -- are carried forward to the second stage, where a model is fitted to the genotype by environment means, using either no weights or weights estimated in the first stage.
#' 
#' * If a *fixed* linear model is used at the second stage, 
#' \[ \*Y = \*X\*b + \*e \quad \quad \mathrm{with}\ e \iid \mathcal{N}(0, \*R = \sigma^2 \*I)\]
#' the (unweighted) solution (Ordinary Least Squares) is 
#' \[ \*b = (^{t}\*X \*X )^{-1} . ^{t}\*X \*Y \]
#' and the weighted solution (Weighted Least Squares) is
#' \[ \*b = (^{t}\*X \*W \*X )^{-1} . ^{t}\*X \*W \*Y \]
#' with $\*W$ the matrix of weights. Here $\*R = \sigma^2 \*W^{-1}$.
#' 
#'    WLS is a special case of Generalized Least Squares (GLS) where all the off-diagonal entries are $0$. This situation arises when the variances of the observed values are unequal (i.e. heteroscedasticity is present), but where no correlations exist among the observed variances. The weight for unit $j$ is proportional to the reciprocal of the variance of the response for unit $j$.
#'
#'    The `gls()` function of package `nlme` allows to fit models with various forms of the variance-covariance matrix of the residuals $\*R$, allowing to account for heteroscedasticity in fixed models. See below.
#' 
#' * If a *mixed* linear model is used at the second stage,
#'  \[ \*Y = \*X\*b + \*Z\*u + \*e \]
#' the solution is
#' \[  \left( \begin{array} {cc}
#'^t\*X\*R^{-1}\*X & ^t\*X\*R^{-1}\*Z \\
#'^t\*Z\*R^{-1}\*X & ^t\*Z\*R^{-1}\*Z + \*G^{-1}
#'\end{array} \right) 
#'\left( \begin{array}{l}
#'\boldsymbol{\hat{b}} \\
#'\boldsymbol{\hat{u}} 
#'\end{array} \right)  = 
#'\begin{pmatrix} 
#'  ^t\*X\*R^{-1}\*y \\
#' ^t\*Z\*R^{-1}\*y 
#'\end{pmatrix}
#'\]
#'\vspace{1\baselineskip}
#'with :
#'\vspace{1\baselineskip}
#'$$ \begin{bmatrix} \*u \\ \*e \end{bmatrix} = \mathcal{N}(\*0, \begin{bmatrix} \*G & \*0 \\ \*0 & \*R \end{bmatrix})$$
#'and $\*R$ and $\*G$ being estimated by Maximum Likelihood (ML) or Restricted Maximum Likelihood (REML).
#' 
#' The random vector $\*u$ contains all random effects pertaining to genotypes and environments, if any.

#' There are several strategies to define the weight matrix ($\*W$ or $\*R$ depending on the model), as described in Möhring & Piepho (2009) *Comparison of Weighting in Two-Stage Analysis of Plant Breeding Trials. Crop Sci. 49, 1977–1988*.
#' 
# read data :
METmaize <- read.table("./METmaize_data.csv", sep = ";", header = TRUE, dec = ",", stringsAsFactors = TRUE)
str(METmaize)

levels(METmaize$Environ)

#' 
#' # Standard methods
#' We will focus on two-stage analyses, starting with using a *fixed* model framework. As such, the variable to analyse is the vector of the means of each $i$ accession in different $j$ environments : $\mu_{ij}$.
#'
#' ## The additive model as the 'null model'
#' 
#' The additive model is
#' \[ \mu_{ij} = \mu + G_i + E_j + \epsilon_{ij} \]
#' Here Genotypes $G_i$ and environments $E_j$ are fixed effects.

Additive <- aov( yield ~ Genotype + Environ, data = METmaize)

#+ figureDiag, include=TRUE, echo=TRUE, out.width = '80%', fig.cap="Graphical diagnostic for residuals of the additive model. \\label{figureDiagAdditive}"
##x11()
par(mfrow = c(2,2))
plot(Additive)
par(mfrow = c(1,1))
#' Residuals are probably following a Normal distribution *but* variances are unlikely to be homogeneous.
shapiro.test(Additive$residuals)

leveneTest(Additive$residuals, METmaize$Genotype)
leveneTest(Additive$residuals, METmaize$Environ)

#' This is a classical finding in MET analyses ! Well, let's say we decide to go on with the analysis ....

summary(Additive)

#' ## Modeling heterogeneous variances among environments.
#' 
#' A solution to the above concern would be to analyse the data using a *weighted fixed* linear model to account for heterogeneous variances.
#+ message = FALSE
library(nlme) ## to fit GLS model
AdditiveHetero <- gls(yield ~ Genotype + Environ, data = METmaize,
                   weights = varIdent(form = ~1 | Environ))  ## different variances per stratum
# getting coefficient for estimated variances per environ.
AdditiveHetero$modelStruct$varStruct 
summary(AdditiveHetero)$sigma
#' the estimated SD  per environ are :
summary(AdditiveHetero)$sigma * AdditiveHetero$modelStruct$varStruct

# overlaps of parameters ?
intervals( AdditiveHetero )$varStruct # LN96a diff from IS92a
intervals( AdditiveHetero )$sigma

anova(AdditiveHetero) ## no SS....

# to compare with addtive w/o heterogeneous variances
AdditiveCste <- gls(yield ~ Genotype + Environ, data = METmaize)

#' Comparing the different models shows that accounting for heterogeneous variances among environments significantly improves the analysis.
anova(AdditiveCste, AdditiveHetero)                     

#' Looking at the residuals of the OLS and GLS additive model suggests that the heterogeneity of the variances between the environments was taken into account with the `gls` method: the residuals are better distributed over the surface, with no particular trend from left to right (Figure \ref{figureCompRes}).
#' 
#+ figureCompRes, include = TRUE, echo = FALSE, out.width = '80%', fig.cap = "Graphical assessment of the residuals of OLS (up) and WLS (bottom) models for GxE data. \\label{figureCompRes}"
x11()
##p1 <- ggplot() + aes( x = Additive$fitted, y = Additive$residuals) + geom_point() + theme_bw() + xlim(c(-1, 8))
p1 <- plot(AdditiveCste, resid(., type = "normalized") ~ fitted(.), pch = 19, cex = 0.6, col = "black")
p2 <- plot(AdditiveHetero, resid(., type = "normalized") ~ fitted(.), pch = 19, cex = 0.6, col = "black")
grid.arrange(p1,p2)

## # box-plots of residuals by environment
## x11()
## p1 <- ggplot() + aes( y = Additive$residuals, x = METmaize$Environ) + geom_boxplot() + coord_flip() + theme_bw()
## p2 <- plot(AdditiveHetero, Environ ~ resid(.))
## grid.arrange(p1,p2)

#' Several points developped in this part will be used when fitting Linear Mixed Models -- LMM.
#'
#' $\blacktriangleright$ Let's compute the predicted values and the interaction values given by the different models. Remember the (GE + residuals) are the residuals of these models.
#'
Predit <- data.frame(Genotype = METmaize$Genotype,
                     Environ = METmaize$Environ,
                     Additive = predict(AdditiveCste),
                     AddHetero= predict(AdditiveHetero))

InteractionEffects <- data.frame(Genotype = METmaize$Genotype,
                     Environ = METmaize$Environ,
                     Additive = residuals(AdditiveCste),
                     AddHetero= residuals(AdditiveHetero))

#' Accounting for heterogeneous variances among environments only slightly modifies the predicted values of the G+E component, and has a more pronounced effect of the GE component (Figure \ref{figureCompHetero}). It would be better to use the predicted values of *GE accounting for heterogeneous variances among environments* for subsequent analyses (e.g. AMMI, GGE).
#+ figureCompHetero, include = TRUE, echo = FALSE, fig.width = 8, fig.cap = "Predicted G+E (left) and GE (right) components, accounting or not for heterogeneous variances among environments. \\label{figureCompHetero}"
x11()
p1 <- ggplot(Predit) + aes( y = Additive, x = AddHetero) +
    geom_point(alpha = 0.6, cex = 1.2, col = "firebrick") + geom_abline(slope = 1, intercept = 0, lty = 5) + 
    facet_wrap( ~ Environ) + theme_bw() +
    labs( x = "additive effects, accounting for \nheterogeneous variances \namong environments", y = "additive effects, w/o accounting for \nheterogeneous variances among environments", title = "")

##x11()
p2 <- ggplot(InteractionEffects) + aes( y = Additive, x = AddHetero) +
    geom_point(alpha = 0.6, cex = 1.2, col = "darkgreen") + geom_abline(slope = 1, intercept = 0, lty = 5) + 
    facet_wrap( ~ Environ) + theme_bw() +
    labs( x = "interaction effects, accounting for \nheterogeneous variances \namong environments", y = "interaction effects, w/o accounting for \nheterogeneous variances among environments", title = "")
#plot the two graph
grid.arrange(p1, p2, ncol = 2)

#' 
#'
#' ## Because we are working with a **table of means**, the model with interaction can **NOT** be fitted.
#'
#' As a matter of fact, the model is
#' \[ \mu_{ij} = \mu + G_i + E_j + (GE_{ij} + \epsilon_{ij}) \]


Complete <- aov( yield ~ Genotype * Environ, data = METmaize)
summary(Complete)
#' The interaction is summed with the residual, there is no MS to use to test the factor effects.
#'
#' ## The Finlay and Wilkinson regression.
#'
#' Also called ''joint regression"" or "regression on the mean". The Finlay and Wilkinson regression (1963) describes GE as a regression line on the environmental quality. In the absence of explicit environmental information, the biological quality of an environment can be reflected in the average performance of all genotypes in that environment. Good environments will have a high average genotypic performance, and bad environments will have a low average genotypic performance. 
#'
#' The GE part is described by genotype-specific regression slopes on the environmental quality, and the model can be written in the following equivalent ways:
#' \[ \mu_{ij} = \mu + G_i + E_j + b_iE_j + \delta_{ij}  \]
#' or
#' \[ \mu_{ij} = G'_i + b'_i E_j + \delta_{ij} \]
#' by taking $\mu + G_i = G'_i$ and $E_j + b_i E_j = (1 + b_i )E_j = b'_i Ej$. This latter model is easier to interpret because it looks as a set of regression lines; each genotype has a linear reaction norm with intercept $G'$ and slope $b'$. Genotypes  are characterized in terms of:
#' 
#' *  intercept (general performance, $\mu_i$)
#' *  slope (adaptability, sensitivity $b'_i$)
#' *  deviations from regression (stability, var($\epsilon$) in each environment)
#'
#'  Note : it would have been better to work using the predicted values of GLS model than with the original raw data.
# environmental indexes, expressed as a deviation from the average :
Indexes <- METmaize %>% group_by(Environ) %>% summarise(Index = mean(yield))
Indexes$Index <- Indexes$Index - mean(METmaize$yield)  ## do not forget
Indexes
#' Environments  can be ranked on their Index : $Index > 0$ : better than average, $E < 0$: worse than average

# shortcut to distribute index over the full table:
METmaize <- left_join(METmaize, Indexes, by = c("Environ" = "Environ") )
head(METmaize)


# Fitting FW regression:
JointReg <- lm( yield ~ Genotype + Environ +  Genotype:Index, data = METmaize)
anova(JointReg)
#' The `Genotype:Index` term is sometimes called `Heterogeneity of slopes`. In the regression on the mean model, GE is explained in terms of differential sensitivities to the improvement of the environment, with some genotypes (the ones with larger values of $b_i$) benefiting more than others from an increase in environmental quality. 
#'
#' To compare with the ANOVA of additive model :
summary(Additive)
#' The GE is "extracted" from the Residual of the Additive model. See df : $1260+210=1470$ and SS: $229.9 + 583.3 = 813$.
#'
#' Let's plot some lines :
#+ figureFW1, include=TRUE, echo=TRUE, fig.cap="Finlay-Wilkinson regression. \\label{figureFW1}"
toto <- data.frame(METmaize, predicted = predict(JointReg))
x11()
toto %>% filter( Genotype %in% c("G025","G045","G016","G012", "G008")) %>% 
    ggplot( aes( x = Index, y = predicted, group = Genotype, colour = Genotype)) +
    geom_line(lwd = 1.5) +
    geom_abline(slope = 1, intercept = mean(METmaize$yield), lty = 2) + geom_vline(xintercept = 0, lty = 2) + 
    theme(plot.background=element_rect(fill="aliceblue"),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm")) #top, right, bottom, left


#' Note that  $b' > 1$ for genotypes with a higher than average sensitivity, and $b'< 1$ for genotypes that are less sensitive than average. Using the $\mu_{ij} = G'_i + b'_i E_j + \delta_{ij}$ form of the FW regreesion, we can compare some genotypes:
coef(JointReg)['(Intercept)'] + coef(JointReg)['GenotypeG025'] ; coef(JointReg)['GenotypeG025:Index'] + 1
coef(JointReg)['(Intercept)'] + coef(JointReg)['GenotypeG045'] ; coef(JointReg)['GenotypeG045:Index'] + 1
coef(JointReg)['(Intercept)'] + coef(JointReg)['GenotypeG008'] ; coef(JointReg)['GenotypeG008:Index'] + 1

#' The model can be used to predict the performance of genotypes in environments that were not present in the MET, as long as the environment for which predictions are required can reasonably be placed within the range of environments used in the original MET. 
#' 
#' The Finlay-Wilkinson procedure can be suboptimal for at least four reasons: (1) in the first step environmental means are typically estimated without considering genetic-by-environment interactions, (2) in the second step uncertainty about the environmental means is ignored, (3) estimation is performed regarding lines and environment as fixed effects, and (4) the procedure does not incorporate genetic (either pedigree-derived or marker-derived) relationships. 
#'
#' 
#' # Bilinear models
#' 
#' Before getting into the details of biliner models, we will explore the concept of 'extracting' information from a matrix based on Singular Value Decomposition. The example will be based on *reconstructing* a picture. **Script**
#'
#' ## the AMMI decomposition of GE
#'
#' The AMMI model is
#' \[ \mu_{ij} = \mu + G_i + E_j + \sum_{k=1}^r (G_{ik} \cdot E_{jk}) + \delta_{ij} \]
#' where the GE is now explained by $k$ multiplicative terms ($k = 1 \ldots r$), each multiplicative term formed by the product of a genotypic sensitivity $G_{ik}$ (genotypic score) and a hypothetical environmental characterization $E_{jk}$ (environmental score).
#'
#' The genotypic and environmental score come from the SVD of the two-way matrix of the interaction terms, with the genotypes as rows and enviroments as coulumns. The SVD of a rectangular matrix $\*A_{m \times n}$ is:
#' \[ \*A = \*U \Lambda\ ^t\*V \]
#' with $\*U_{m \times m}$ the *left-singular* vectors, $\Lambda_{m \times n}$ the matrix of the *singular values* and $\*V_{n \times n}$ the *right-singular* vectors. We usually force $\*U \cdot ^t\*U = \*V \cdot ^t\*V = \*I$.
#' 

#' 
# Getting the table of interaction values
Additive2 <- aov(yield ~ Genotype + Environ + Genotype:Environ, data = METmaize)
modelTables <- model.tables(Additive2, type = "effects", cterms = "Genotype:Environ")
interaction.effects <- modelTables$tables$"Genotype:Environ"  ## to get the table of interactions
head(interaction.effects)

## SVD
## let's use the 8 eigenvectors
PC <- 8
decomposition <- svd(interaction.effects, nu = PC, nv = PC)

if (PC > 1) {
D <- diag(decomposition$d[1:PC])
} else {
D <- decomposition$d[1:PC]  ## because of diag()
}
D

#' We can illustrate the full reconstruction using the $8$ eigen vectors, by forming $\*u\cdot \*D\cdot ^t\*v$.
interaction.effects[1:7, 1:5 ]
reconstruction <- decomposition$u %*% D %*% t(decomposition$v)  ## be careful, use t(v)
reconstruction[ 1:7, 1:5]
## if needed, check that uDv does NOT give the correct results.

## let's use 2 eigenvectors to approximate the GE matrix
PC <- 2
decomposition <- svd(interaction.effects, nu = PC, nv = PC)
str(decomposition)

if (PC > 1) {
D <- diag(decomposition$d[1:PC])
} else {
D <- decomposition$d[1:PC]  ## because of diag()
}
D

# Show the approximation using 2 eigen vectors
interaction.effects[1:7, 1:5 ]
reconstruction <- decomposition$u %*% D %*% t(decomposition$v)
reconstruction[ 1:7, 1:5]

# percentage of information using 2 eigen vectors
sum(decomposition$d[1:2])/sum(decomposition$d)  ## not really great
#' Rewriting
#' \[ GE = \sum_{k=1}^r u_{ik} \lambda_k \ ^tv_{jk} = \sum_{k=1}^r (u_{ik} \sqrt{\lambda_k})\cdot (^tv_{jk} \sqrt{\lambda_k})= \sum_{i=1}^r G_{ik} E_{jk} \]
#' with $r$ the rank of the GE matrix (minimum of the number of genotypes or of the number of environments), gives a *multiplicative* decomposition of the GE matrix. $G_{ik}$ is the genotypic sensitivity (genotypic score), and $E_{jk}$ is a hypothetical environmental characterization (environmental score) for each of the 'principal components'.

f <- 0.50  ## A classical partitioning for AMMI (see below GGE), called symmetrical partitioning
G <- decomposition$u %*% D^(f)
E <- decomposition$v %*% D^(1-f)

#' The below code is provided 'as is'. It allows to understand the computation of the ANOVA table of the AMMI decomposition.
Ecolnumb <- c(1:PC)  ## number of retained PCs. Required for df computations
Ecolnames <- paste("PC", Ecolnumb, sep = "")
dimnames(E) <- list(levels(METmaize$Environ), Ecolnames)
dimnames(G) <- list(levels(METmaize$Genotype), Ecolnames)

## Significance of PCs
var.num <- length(levels(METmaize$Genotype))
envir.num <- length(levels(METmaize$Environ))

interaction.SS <- t(as.vector(interaction.effects)) %*% as.vector(interaction.effects) # by definition
## singular values are sqrt or eigenvalues.
## eigenvalues are the variance explained by a PC axis. They are thus SS
( PC.SS <- ( decomposition$d[1:PC] ^2) )
( PC.DF <- var.num + envir.num - 1 - 2 * Ecolnumb )  ## loosely explain in Gollob (1968) 
## A statistical model which combines features of factor analytic and analysis of variance techniques. Psychometrika 33, 73:115. https://doi.org/10.1007/BF02289676

## extraction of PC.SS from interaction.SS
residual.SS <- interaction.SS - sum(PC.SS)
residual.DF <- ((var.num - 1) * (envir.num - 1)) - sum(PC.DF)

PC.SS[PC + 1] <- residual.SS  # add a pc+1 line to contain that SS
PC.DF[PC + 1] <- residual.DF  # add a pc+1 line to contain that DF
MS <- PC.SS / PC.DF
F <- MS / (deviance(Additive) / Additive$df.residual)    ## the GxE MS of initial additive model is used to compute F values
Fbis <-  MS / MS[PC + 1]                         ## The 'residual' MS of current analysis is used to compute F values

proba <- pf(F, PC.DF, Additive$df.residual, lower.tail = FALSE)
probab <- pf(Fbis, PC.DF, PC.DF[ PC +1], lower.tail = FALSE)

( percSS <- PC.SS / interaction.SS )
rowlabels <- c(Ecolnames, "Residuals")

( AMMI.anova <- data.frame(Effect = rowlabels, d.f. = PC.DF, SS = PC.SS, MS = MS, F = F, Prob. = proba) )

#'
#' $\blacktriangleright$ If only one PC is kept, the method is called AMMI1 (Figure \ref{AMMI1}).
#'
#' The AMMI1 biplot shows contemporarily main effects (genotypes and environments average yields) and interaction, as PC1 scores. To read this biplot, it is necessary to remember that genotypes and environments on the right side of the graph shows yield levels above the average. Besides, genotypes and environments laying close to the x-axis (PC 1 score close to 0) did not interact with each other, while data with positive/negative score on y-axis interacted positively with environments characterised by a score of same sign.
#'
#+ figureAMMI1, include=TRUE, echo=FALSE, fig.width = 6, fig.height = 6, fig.cap="AMMI1 biplot. \\label{AMMI1}"
## to match with graphical representation of Malosetti et al. 2013
E <- data.frame(E); G <- data.frame(G) 
E$PC1 <- E$PC1 * (-1) ; G$PC1 <- -G$PC1

envir.mean <- model.tables(Additive, type = "mean")$tables$Environ
var.mean <- model.tables(Additive, type = "mean")$tables$Genotype
overall.mean <- model.tables(Additive, type = "mean")$tables$'Grand mean'

x11()
par(mar = c(4,6,2,2))
plot(NULL, type = 'n', xlim = range(c(envir.mean, var.mean)), ylim = range(c(E[,1], G[,1])),
     xlab = "Yield", ylab = "PC 1")

points(var.mean, G[,1], pch = 21, cex = 1.5,
       col = "black", bg =  alpha("grey",0.3))
#text(var.mean, G[,1], labels = row.names(var.mean), adj = c(0.5, 0.5), col = "blue")

#points(envir.mean, E[,1], pch = 12, col = "red")
text(envir.mean, E[,1], labels = row.names(envir.mean), adj = c(0.5, 0.5), col = "red")
abline(h = 0, v = overall.mean, lty = 5)
#'
#' $\blacktriangleright$ If two PCs are kept, the method is called AMMI2 (Figure \ref{AMMI2}). These biplots facilitate the exploration of relationships between genotypes and/or environments.
#+ figureAMMI2, include=TRUE, echo=FALSE, message = FALSE, fig.width = 6, fig.height = 6, fig.cap="AMMI2 biplot. \\label{AMMI2}"
x11()
par(mar = c(4,6,2,2), pty = "s")
plot(NULL, xlim = range(c(E[,1], G[,1], E[,2], G[,2])), ylim = range(c(E[,1], G[,1], E[,2], G[,2])),
     xlab = "PC 1", ylab = "PC 2")

points(G[,1], G[,2], pch = 21, cex = 1,
       col = "black", bg =  alpha("grey",0.3))
#text(G[,1], G[,2], labels = row.names(G),adj = c(0.5, 0.5), col = "blue")
abline(h = 0, v = 0, lty = 5)

points(E[,1], E[,2], pch = 18, col = alpha("blue", 0.4), cex = 4)
text(E[,1], E[,2], labels = row.names(E), pos = 3, offset = 0.7, col = "red")

pentes <- c( E[, 2]/ E[, 1] )  ## pente = deltaY/deltaX
sapply(pentes, function(x){abline(0, x, col = "blue")})

## en reprenant des exemples d'AlgLin de 1A (2005; page 6)
ProjectAndDraw <- function(a, b, id = NULL){
    a <- as.vector(t(a)) ; b <- as.vector(t(b))
    ## projection of b on a, expressed as a, using scalar product
    pbaa <- (t(a)%*% b) / (t(a) %*% a)
    ## projection of b on a, expressed in the canonical base
    pba <- (t(a)%*% b) / (t(a) %*% a ) * a
    text(b[1], b[2], id, pos = 1, offset = 0.5)
    points( pba[1], pba[2], pch = 19, col = "red", cex = 1)
    segments( b[1], b[2], pba[1], pba[2], lty = 5, col = "red")
    }

ProjectAndDraw( E[row.names(E) == "NS92a",], G[row.names(G) == "G041",], "G041")
ProjectAndDraw( E[row.names(E) == "NS92a",], G[row.names(G) == "G091",], "G091")
ProjectAndDraw( E[row.names(E) == "LN96a",], G[row.names(G) == "G091",])
ProjectAndDraw( E[row.names(E) == "LN96b",], G[row.names(G) == "G091",])

#'
#' * Genotypes/environments that are alike tend to cluster together.
#' * The angle between environmental axes is related to the correlation between the environments. An acute angle indicates positive correlation (e.g., between LN96a and LN96b), a right angle indicates no correlation (e.g., between HN96b and NS92a), and an obtuse angle indicates negative correlation (e.g., NS92a and LN96a).
#' * The projection of a genotype onto an environmental axis reflects the performance of that genotype in that environment (for GEI). For example, genotype G091 projects on the NS92a axis above the origin, indicating a positive interaction with that environment i.e., the relative performance (GEI part) of G091 in NS92a is above the average of all genotypes in NS92a. Conversely, genotype G041 (on the right hand side of the plot) projects below the origin on the same axis, which points to a negative interaction with environment NS92a (i.e., G041 performs worse than average).
#' * Following a similar procedure it is possible to conclude that while genotype G091 showed positive adaptation to environment NS92a, it is not well adapted to environments LN96a and LN96b (the projection of G091 on the LN96a and LN96b axes falls below the origin). Biplots are thus useful tools to investigate patterns in GEI, because they can help to identify interesting genotypes that are adapted to particular environments, and to classify environments in groups.
#'
#' The `agricolae` package has a `AMMI` function. The `plantbreeding` package has also a `ammi.full` function. **Both require to have data with replicates per environment , typically `blocks within locations'**.
#' 
#' ## The GGE decomposition of GE
#' As a matter of fact the AMMI method is a particular case of a more general method aiming to decompose the information in a matrix using SVD. Given a genotype by environment two-way table $\*P$ of $m$ genotypes and $n$ environments, and using the classical two-way ANOVA model $\mu_{ij} = \mu + \alpha_i + \beta_j + \gamma_{ij}$, with $\alpha_i$ the effect of the genotype, $\beta_j$ the effect of the environment and $\gamma_{ij}$ the interaction effect, we would write :
#'
#'\begin{align}
#' P_{ij} &= \mu_{ij} = \mu + \alpha_i + \beta_j + \gamma_{ij} \\
#' P_{ij} &= \mu_{ij} - \mu = \alpha_i + \beta_j + \gamma_{ij} \\
#' P_{ij} &= \mu_{ij} - \mu - \alpha_i = \beta_j + \gamma_{ij} \\
#' P_{ij} &= \mu_{ij} - \mu - \beta_j  = \alpha_i + \gamma_{ij} \\
#' P_{ij} &= \mu_{ij} - \mu - \alpha_i - \beta_j  = \gamma_{ij} 
#'\end{align}
#'
#' The AMMI method corresponds to the SVD decomposition of the GE-matrix (Eq. 5). If one is interested in geno-type evaluation, Eq. 4 is also appropriate, as it contains both G and GE, which can be considered simultaneously.  Biplots based on Eq. 4 are referred to as "GGE biplots". Other models above are know as completely multiplicative model (COMM - Eq. 2), and shifted multiplicative model (SHMM - Eq. 3).

#'
#'A second point to consider is the so-called 'partitioning of the singular value' into the genotype ($\xi_{ik}^*$) and environment ($\eta_{jk}^*$) scores before a biplot can be constructed to approximate the two-way table:

#'\[ P_{ij} = \sum_{k=1}^r \xi_{ik}^*\eta_{jk}^* = \sum_{k=1}^r \left( \xi_{ik}\lambda_k^f \right) \left( \eta_{jk}\lambda_k^{1-f} \right) \]
#' Note that the partitionning for AMMI is classicaly $f=0.5$, called symmetrical partitioning (see above example).
#' 
#' \textbullet  When $f = 0$, the singular values are entirely partitioned into the column (here environment) eigenvectors, referred to column-metric preserving.
#' 
#' \textbullet  When $f =1$, the singular values are entirely partitioned into the row eigenvectors, which is referred to as row-metric preserving. It is, therefore, appropriate for visualizing the similarity/dissimilarity among row factors (here genotypes).
#'
#' A third point to consider is the 'scaling' of the data. The GGE biplot model (Eq. 4) can be more generally presented as:
#' \[ P_{ij} = (\mu_{ij} - \mu - \beta_j) / s_{j}  = ( \alpha_i + \gamma_{ij}) / s_{j}  \] where $s_j$ is a scaling factor. When $s_j$ is the standard error for environment $j$, any heterogeneity among the environments will (supposedly) be removed.
#'
#' Getting the two-way table ready for the diverse analyses is as simple as getting the two-table of the residuals of each model. Example for GGE :
# the Pij matrix is the residual of :
ModelPrGGE <- aov( yield ~ Environ, data = METmaize)
Resids <- cbind(METmaize, prGGE = ModelPrGGE$residuals)          
t(Resids$prGGE) %*% Resids$prGGE  ## compare to sum of Genotype and G:E SS of Additive2
# here is the table to subject to SVD for GGE analysis (long to wide) :
GGEready <- Resids %>% select(Genotype, Environ, prGGE) %>% pivot_wider(names_from = Environ, values_from = prGGE)
head(GGEready)

#'
#' 
#' $\blacktriangleright$ **Using a simpler dataset for ease of interpretation, let's try a GGE biplot analysis aiming to compare genotypes of $18$ winter wheat genotypes assessed at $9$ places in Canada-Ontario (in ton.ha$^{-1}$)**.
#' 
#' The `gge` and `GGEBiplots`(based on `gge`) R packages may be useful. The `gge` package allows for principal component analysis (SVD) of a data table that can contain missing value, using the Non-linear Iterative Partial Least Squares (NIPALS) algorithm. 

METwheat <- read.table("METwheat_data.csv", sep = ";", dec = ".", header = TRUE, stringsAsFactors = TRUE) ##  achtung ! two-way table
head(METwheat)
# wide to long
METwheatLong <- METwheat %>% pivot_longer(c(E1, E2, E3, E4, E5, E6, E7, E8, E9),
                                          names_to = "Environ",
                                          values_to = "yield")
## GGE analysis
library(gge)
m1 <- gge(METwheatLong, yield ~ Genotype * Environ, scale = FALSE)
#+ figureGGE1, include=TRUE, echo=FALSE, message = FALSE, fig.width = 6, fig.height = 6, fig.cap="GGE biplot: 'Which-Won-Where' of the winter wheat MET dataset, `gge` package. \\label{GGE1}"
x11()
biplot(m1, main = "maize MET - GGE biplot",
       flip =  c(1,1), origin = 0, hull = TRUE)
#'
#' Figure \ref{GGE1} shows a "which-won-where" graph:  A polygon is first drawn on genotypes that are furthest from the biplot origin so that all other genotypes are contained within the polygon. Then perpendicular lines to each side of the polygon are drawn, starting from the biplot origin.
#'
#' The interpretations are as follows:
#' 
#' 1. Genotypes located on the vertices of the polygon performed either the best or the poorest in one or more environments.
#' 2. The perpendicular lines are equality lines between adjacent genotypes on the polygon, which facilitate visual comparison of them.
#' For example, the equality line between G18 and G8 indicates that G18 was better in E7 and E5, whereas G8 was better in the other environments. The equality line between G18 and G7 indicates that G18 was better than G7 in all environments. Note that G3 and G1 are located on the line that connects G18 and G7. This means that the rank G18 $>$ G3 $>$ G1 $>$ G7 was true in all environments.
#' 3. The equality lines divide the biplot into sectors, and the winning genotype for each sector is the one located on the respective vertex. In this example, the nine environments fall into *two sectors*. G18 was the winner in environments E7 and E5, and G8 was the winner for the other environments. This pattern suggests that the target environment may consist of *two* different *mega-environments* and that different cultivars should be selected and deployed for each.
#' 
#' For the "which-won-where" graph, the *environment-focused partitioning* is preferred because it correctly shows the relationships among environments.
#' 
#' $\blacktriangleright$ `GGEBiplots` can fit all models (AMMI, GGE, etc..) and allows for more flexibility in partionning. See package documentation. However, the quality of graphs is not really high (Figure \ref{GGE2}). Going back to the maize MET dataset to visualize a GGE biplot analysis with *genotype-focused partitioning* and no scaling of environments :
library(GGEBiplots)
# need to re-organize raw data as a two-way table : from long to wide
GGEready2 <- data.frame(METmaize %>% select(Genotype, Environ, yield) %>%
                        pivot_wider(names_from = Environ, values_from = yield))
rownames(GGEready2) <- GGEready2$Genotype
GGEready2 <- GGEready2[, -1]
head(GGEready2)

# a GGE biplot with genotype-metric preserving partitioning and no scaling
m2 <- GGEModel(GGEready2, centering = "tester", # GGE
               scaling = "none",
               SVP = "row") # genotype-preserving partitioning

#+ figureGGE2, include=TRUE, echo=FALSE, message = FALSE, fig.width = 6, fig.height = 6, fig.cap="GGE biplot: 'Which-Won-Where' of the maize MET dataset, `GGEBiplots` package. \\label{GGE2}"
x11()
WhichWon(m2) + theme(aspect.ratio = 1)

#' \textbullet Typically, GGE analysis allows to address the following  questions:
#'
#' 1. Can the target environment be divided into meaningful mega-environments so that some of the GE can be exploited or avoided? Multi-year data are essential to address this question.
#' 2.  What are the best test environments (representative and discriminating)?
#' 3.  What are the superior genotypes (both high and stable performance within a mega-environment)?
#'
#' 
#' # Factorial regression
#'
#' If we do have explicit information about the environment, the information can be used directly in the model by including it in the form of explanatory variables. GE is then described as differential genotypic sensitivity to explicit environmental factors such as temperature, precipitation, water availability etc. Such models are known as factorial regression models.
#'
#' Formally, they are simply linear models where the G $\times$ E is partitioned into several G $\times$ covariate interactions.
#'
#' The maize MET data set has two covariates that will be used to predict genotypic means :

FactReg <- lm( yield ~ Genotype + Environ + Genotype:MINTF + Genotype:RADG,
              data = METmaize)
anova(FactReg)

#' Here, the GE is explained by differential genotypic sensitivities to the minimum temperature during flowering and to the amount of radiation during grain filling.
#' 
#' $\blacktriangleright$ You may be confronted to the situation that there are many, possibly correlated, predictor variables, and relatively few samples/sites. This a situation that is common especially in so-called 'enviro-typing' analyses, where attempts are made to identify and characterise the TPE.
#'
#' Multivariate regression methods like Principal Component Regression (PCR) and Partial Least Squares Regression (PLSR or PLS) enjoy currently a large popularity in some companies. The main reason is that they have been designed to handle these situations. 
#' The `pls` R package implements Principal Component Regression (PCR) and Partial Least Squares Regression (PLSR). The user interface is modelled after the traditional formula interface, as exemplified by `lm`. 
#'
#' 
#' # Mixed models
#'
#' The models considered so far focus on modeling the mean response.  We are switching to the framework of so-called *mixed models*. Mixed models are a powerful alternative, as they easily handle missing data (i.e., not all combinations of G and E explored). Mixed models can be used to model GE in terms of heterogeneity of variance and covariance. (Smith, A.B., Cullis, B.R., Thompson, R., 2005. The analysis of crop cultivar breeding and evaluation trials: an overview of current mixed model approaches. The Journal of Agricultural Science 143, 449.)

#' 
#' As a matter of fact, the correlations of the phenotypic values in the different sites is a quantity of interest. Let's explore the correlations among environments at first (Figure \ref{corr1}).
#' 
#+ figureCorr1, include = TRUE, echo = FALSE, message = FALSE, fig.width = 6, fig.height = 6, fig.cap = "Phenotypic correlations for yield, for 211 maize lines assessed in eight environments. \\label{corr1}"
x11()
ggpairs(GGEready,
          columns = 2:9,
          lower = list(
              continuous = wrap(color = "darkgreen", "points",alpha = 0.4))) +
    theme(panel.grid.major = element_blank())
#'
#' As with all mixed models, key is the assumed covariance structure (the correlations being only the covariance scaled by the variances of each environment) among the genotypes and/or environments. 
#' As shown previously, the *mixed* linear model is,
#' 
#'  \[ \*Y = \*X\*b + \*Z\*u + \*e \]
#' the solution is
#' \[  \left( \begin{array} {cc}
#'^t\*X\*R^{-1}\*X & ^t\*X\*R^{-1}\*Z \\
#'^t\*Z\*R^{-1}\*X & ^t\*Z\*R^{-1}\*Z + \*G^{-1}
#'\end{array} \right) 
#'\left( \begin{array}{l}
#'\boldsymbol{\hat{b}} \\
#'\boldsymbol{\hat{u}} 
#'\end{array} \right)  = 
#'\begin{pmatrix} 
#'  ^t\*X\*R^{-1}\*y \\
#' ^t\*Z\*R^{-1}\*y 
#'\end{pmatrix}
#'\]
#'\vspace{1\baselineskip}
#'with :
#'\vspace{1\baselineskip}
#'$$ \begin{bmatrix} \*u \\ \*e \end{bmatrix} = \mathcal{N}(\*0, \begin{bmatrix} \*G & \*0 \\ \*0 & \*R \end{bmatrix})$$
#'and $\*R$ and $\*G$ being estimated by Maximum Likelihood (ML) or Restricted Maximum Likelihood (REML).
#' 
#' The random vector $\*u$ contains all random effects pertaining to genotypes and environments, if any. 
#'
#' Most important to consider is the variance-covariance matrix of the response vector $\*y$:
#' \[   \textrm{Var}(\*y) =  \*Z \*G ^t\*Z + \*R   \]
#'
#' ## Fitting LMM using `lme4` : the compound symetry model.
#' `lme4` allows to fit model with *crossed random effects* **but** does not allow to set particular structure to the $\*G$ and $\*R$ matrices. It is thus not possible to account for heterogeneous variances among environments in the residuals, or to account for the genetic relationships among genotypes for example.
#'
#' *Crossed random effects* shall be understood as random effects *crossed with each others*, for example a MET where Genotypes and Environments are considered as random. Another example is a MET with several measurements of the Genotypes in each Environments (typically, values of a RCBD in each environment) where  Genotypes and Blocks are considered as random and Environments as fixed, the GxE being also a random effect. Here the Block and Genotype effects are crossed with each other, and Genotype effects and GxE effects are also random crossed effects.
#'
#' Let's fit a LMM with environments considered as fixed effects and genotypes as random effects. As such, this model do not really need to be fitted using `lme4` because there is no crossed random effects with each other, but it is way to understand the process. We will get a value for the genetic variance $\sigma_g^2$.
#'
#' It is always usefull to compute the size of the different matrices of the design:
#' \[ \*Y_{(1688, 1)} = \*X_{(1688, 8)}\*b_{(8, 1)} + \*Z_{(1688, 211)}\*u_{(211, 1)} + \*e_{(1688, 1)} \] and $\*G_{(211, 211)}$, $\*R_{(1688, 1688)}$
#+ message = FALSE
library(lme4)
METmaizeTri <- METmaize[order(METmaize$Genotype, METmaize$Environ),]
head(METmaizeTri, 12)
## fit the LMM:
lmm1 <- lmer( yield ~ Environ + (1|Genotype), data = METmaizeTri)
lmm1
VarCorr(lmm1) ## get the variance components (as sd ....)
#' With this model, we are restricted to the situation where $\*G = \sigma_g^2 \*I = 0.297\cdot\*I$ and $\*R = \sigma_e^2 \*I = 0.554\cdot\*I$.
#'
#' An important consequence of including genotypes as random is that *automatically* genetic covariances and correlations between performances in different environments *are imposed*, that depend on the structure of $\*G$ and $\*R$. Let's compute $\textrm{Var}(\*y)$ to see the consequences in that particular model :
Z <- lme4::getME(lmm1,'Z')
dim(Z) ## as expected 
Vy <- Z %*% (0.297 * diag(211)) %*% t(Z) + 0.554 * diag(1688) 
Vy[1:12, 1:12]

#' Following $P = G + E$, the total variance for individual phenotypic observations in a particular environment $j$, $\sigma_j^2$, is the sum of two sources of variation: $\sigma_j^2 = \sigma_G^2 + \sigma_e^2$. From the model, the covariance between observations for a particular genotype in environments $j$ and $j'$ is $\sigma_{jj'} = \sigma_G^2$. For observations on different genotypes $\sigma_{jj'} = 0$.
#'
#' So, with this model, similarities (or covariation, and therefore correlation) between observations made on the same genotype in different environments are assumed to be identical and positive, but covariation between observations on different genotypes (regardless whether the observation is done in the same or in different environments) is assumed to be zero. This model is referred as the *compound symmetry model*. 

#'
#' The model imposes a constant correlation between environments, with the correlation between any pair of environments $j$ and $j'$, being equal to:
#'\[ \mathrm{r}_{(j,j')} = \frac{\sigma_{jj'}}{\sqrt{\sigma_j^2} \sqrt{\sigma_{j'}^2}} =  \frac{\sigma_G^2}{ \sqrt{\sigma_G^2 + \sigma_e^2} \sqrt{\sigma_G^2 + \sigma_e^2}}  = \frac{\sigma_G^2}{\sigma_G^2 + \sigma_e^2} = H^2\]
#' This is the genetic correlation between any two environments.

#'
#' ## Fitting LMM with heterogeneous environmental variances
#' The *compound symmetry model* assumes a constant genetic variance and correlation between pairs of environments. For METs, the assumption of constant genetic variance and genetic correlation across environments is unrealistic. In the presence of GE, a more realistic model would allow the total genetic variance to change from environment to environment, which will in turn, cause heterogeneous genetic correlations between environments.
#'
#' Because we are considering the environment as a fixed effect here, we will model the heterogeneity of environments in the $\*R$ matrix (see the example of --fixed-- GLS with heterogeneous variances for environments). Because `lme4` does not allow to impose structures on the $\*R$ matrix, we will use the `nlme::lme()` function.

# baseline : compound symmetry model with nlme::lme
lmm1b <- lme( yield ~ Environ, data = METmaizeTri,
            random = ~ 1 | Genotype
            )
lmm1b

# model with heterogeneous variances among environ.
lmm2 <- lme( yield ~ Environ, data = METmaizeTri,
            random = ~ 1 | Genotype,
            weights = varIdent(form = ~1 | Environ) ## for R matrix
            )
lmm2
VarCorr(lmm2)
lmm2$modelStruct$varStruct

anova(lmm1b, lmm2)
#' Model `lmm2` is significantly better, even it has more parameters. Let's compute $\textrm{Var}(\*y)$:
G <- 0.125 * diag(211)
# to compute R
D <- lmm2$sigma^2 * diag(c(1.000, 0.954, 0.940, 0.420, 0.447, 1.356, 0.851, 0.962 ))
dimnames(D) <- list(x = c("HN96b", "IS92a", "IS94a", "LN96a", "LN96b", "NS92a", "SS92a", "SS94a"),
                    y = c("HN96b", "IS92a", "IS94a", "LN96a", "LN96b", "NS92a", "SS92a", "SS94a"))
D                        
R <- kronecker(diag(211), D)
#' The Kronecker product is written $\*I_{211} \otimes \*D$.
dim(R)
R[1:12, 1:12]

Vy <- Z %*% G %*% t(Z) + R
Vy[1:12, 1:12]

#' There is still a single genetic variance component for genotypes, and therefore, a *constant genetic covariance* between environments. However, the variance for the term $\epsilon_{ij}$ that includes GE and error, is assumed to depend on the environment. Instead of two variance components, there are now nine, one corresponding to the variance component for genotypes ($\sigma_g^2 = 0.125$), and eight corresponding to a form of GE for each of the eight environments. The heterogeneity of variance for $\epsilon_{ij}$ reflects that in some environments there is a larger variation (e.g. in environment NS92a, which is the high-yielding ) than in other environments (e.g., in environments LN96a and LN96b which are low-yielding).
#'
#' The heterogeneity of variance leads to heterogeneous genetic correlations between environments. For example, the correlation between environments NS92a and SS92a is:
#'\[ \textrm{r}_{6,7} = \frac{\sigma_G^2}{\sqrt{\sigma_G^2 + \sigma_6^2 } \sqrt{\sigma_G^2 + \sigma_7^2}} = \frac{0.125}{\sqrt{0.125 + 1.03 } \sqrt{0.125 + 0.647}} = 0.132   \]
#' 
#' and between environments 1 and 2 is:
#' \[ \textrm{r}_{1,2} = \frac{\sigma_G^2}{\sqrt{\sigma_G^2 + \sigma_1^2 } \sqrt{\sigma_G^2 + \sigma_2^2}} = \frac{0.125}{\sqrt{0.125 + 0.761 } \sqrt{0.125 + 0.726}} =  0.144  \]
#'
#' In conclusion, this model accommodates heterogeneity of variance between environments and, with it, allows for heterogeneous correlations between environments, which can be desirable when analyzing environments that strongly differ (e.g., with strong stress and without stress).
#'
#' ## Fitting a stability variance model
#'
#' If we have data from RCBD in each environments, a good candidate model for data analyses is the following linear model:
#' \[ y_{ijk} = \mu + \gamma_{kj} + g_i + e_j + ge_{ij} + \epsilon_{ijk}  \]

#' where $y_{ijk}$ is yield (or other trait) for the $k$-th block, $i$-th genotype and $j$-th environment, $\mu$  is the intercept, $\gamma_{kj}$ is the effect of the $k$-th block in the $j$-th environment, $g_i$ is the effect of the $i$-th genotype, $e_j$ is the effect of the $j$-th environment, $ge_{ij}$ is the interaction effect of the $i$-th genotype and $j$-th environment, while $\epsilon_{ijk}$ is the residual random term, with variance $\sigma^2$.
#'
#' The block effect, the environment effect and the 'genotype x environment' interaction are usually regarded as random. Therefore, they are assumed as normally distributed, with means equal to 0 and variances respectively equal to $\sigma_{\gamma}^2$,  $\sigma_{e}^2$ and  $\sigma_{ge}^2$.
#'
#' Let's concentrate on $\sigma_{ge}^2$. It is clear that this value is a measure of instability: if it is high, genotypes may respond differently to different environments. In this way, each genotype can be favored in some specific environments and disfavored in some others. Shukla (1974) has suggested that we should allow $\sigma_{ge}^2$ assume a different value for each genotype and use these components as a measure of stability (stability variances). According to Shukla, a genotype is considered stable when its stability variance is lower than $\sigma^2$. That stability variances can be obtained within the mixed model framework.
#'
#' As we have to model the variance-covariance of random effects, we need to use the `lme` function in the `nlme` package. The problem is that random effects are crossed and they are not easily coded with this package, but is is *still* possible. 
#'
#'
#'   _________________
#' 
#'  $\blacktriangleright$ The main advantage of `nlme` relative to `lme4` is a user interface for fitting models with structure in the residuals (various forms of heteroscedasticity and autocorrelation) and in the random-effects covariance matrices (e.g., compound symmetric models).
#'
#'
#' 

